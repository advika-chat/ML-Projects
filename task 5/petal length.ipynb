{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/mnt/data/Iris.csv'\n",
    "iris_data = pd.read_csv(file_path)\n",
    "\n",
    "# Prepare the data\n",
    "X = iris_data.drop(columns=['Id', 'Species'])\n",
    "y = iris_data['Species']\n",
    "\n",
    "# Encode the class labels as integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the structure of the tree node\n",
    "class TreeNode:\n",
    "    def __init__(self, gini, num_samples, num_samples_per_class, predicted_class):\n",
    "        self.gini = gini\n",
    "        self.num_samples = num_samples\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.predicted_class = predicted_class\n",
    "        self.feature_index = 0\n",
    "        self.threshold = 0\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "# Function to calculate the Gini index\n",
    "def gini_index(y):\n",
    "    m = len(y)\n",
    "    return 1.0 - sum((np.sum(y == c) / m) ** 2 for c in np.unique(y))\n",
    "\n",
    "# Function to find the best split\n",
    "def best_split(X, y):\n",
    "    m, n = X.shape\n",
    "    if m <= 1:\n",
    "        return None, None\n",
    "\n",
    "    num_classes = len(np.unique(y))\n",
    "    num_parent = [np.sum(y == c) for c in range(num_classes)]\n",
    "    best_gini = 1.0 - sum((num / m) ** 2 for num in num_parent)\n",
    "    best_idx, best_thr = None, None\n",
    "\n",
    "    for idx in range(n):\n",
    "        thresholds, classes = zip(*sorted(zip(X[:, idx], y)))\n",
    "        num_left = [0] * num_classes\n",
    "        num_right = num_parent.copy()\n",
    "        for i in range(1, m):\n",
    "            c = classes[i - 1]\n",
    "            num_left[c] += 1\n",
    "            num_right[c] -= 1\n",
    "            gini_left = 1.0 - sum((num_left[x] / i) ** 2 for x in range(num_classes))\n",
    "            gini_right = 1.0 - sum((num_right[x] / (m - i)) ** 2 for x in range(num_classes))\n",
    "            gini = (i * gini_left + (m - i) * gini_right) / m\n",
    "            if thresholds[i] == thresholds[i - 1]:\n",
    "                continue\n",
    "            if gini < best_gini:\n",
    "                best_gini = gini\n",
    "                best_idx = idx\n",
    "                best_thr = (thresholds[i] + thresholds[i - 1]) / 2\n",
    "    return best_idx, best_thr\n",
    "\n",
    "# Recursive function to build the tree\n",
    "def build_tree(X, y, depth=0, max_depth=10):\n",
    "    num_samples_per_class = [np.sum(y == i) for i in range(len(np.unique(y)))]\n",
    "    predicted_class = np.argmax(num_samples_per_class)\n",
    "    node = TreeNode(\n",
    "        gini=gini_index(y),\n",
    "        num_samples=len(y),\n",
    "        num_samples_per_class=num_samples_per_class,\n",
    "        predicted_class=predicted_class,\n",
    "    )\n",
    "\n",
    "    if depth < max_depth:\n",
    "        idx, thr = best_split(X, y)\n",
    "        if idx is not None:\n",
    "            indices_left = X[:, idx] < thr\n",
    "            X_left, y_left = X[indices_left], y[indices_left]\n",
    "            X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "            node.feature_index = idx\n",
    "            node.threshold = thr\n",
    "            node.left = build_tree(X_left, y_left, depth + 1, max_depth)\n",
    "            node.right = build_tree(X_right, y_right, depth + 1, max_depth)\n",
    "    return node\n",
    "\n",
    "# Train the decision tree\n",
    "tree = build_tree(X_train.values, y_train)\n",
    "\n",
    "# Function to print the tree\n",
    "def print_tree(node, depth=0):\n",
    "    if node is not None:\n",
    "        print(f\"{'|   ' * depth}Node(depth={depth}, gini={node.gini:.4f}, samples={node.num_samples}, value={node.num_samples_per_class}, class={node.predicted_class})\")\n",
    "        if node.left is not None or node.right is not None:\n",
    "            print(f\"{'|   ' * depth} feature_{node.feature_index} <= {node.threshold:.4f}\")\n",
    "            print_tree(node.left, depth + 1)\n",
    "            print(f\"{'|   ' * depth} feature_{node.feature_index} > {node.threshold:.4f}\")\n",
    "            print_tree(node.right, depth + 1)\n",
    "\n",
    "# Function to make predictions\n",
    "def predict_tree(node, X):\n",
    "    if node.left is None and node.right is None:\n",
    "        return node.predicted_class\n",
    "    if X[node.feature_index] <= node.threshold:\n",
    "        return predict_tree(node.left, X)\n",
    "    else:\n",
    "        return predict_tree(node.right, X)\n",
    "\n",
    "# Print the tree structure\n",
    "print_tree(tree)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = [predict_tree(tree, x) for x in X_test.values]\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
